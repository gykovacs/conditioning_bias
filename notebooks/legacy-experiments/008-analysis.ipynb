{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (binclas_datasets, regr_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "binclas_datasets = binclas_datasets.drop('data_loader_function', axis='columns')\n",
    "regr_datasets = regr_datasets.drop('data_loader_function', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binclas_datasets['name'] = binclas_datasets[['name', 'citation_key']].apply(lambda x: f'{x[\"name\"]} \\\\cite{{{x[\"citation_key\"]}}}', axis=1)\n",
    "binclas_datasets = binclas_datasets.drop('citation_key', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_datasets['name'] = regr_datasets[['name', 'citation_key']].apply(lambda x: f'{x[\"name\"]} \\\\cite{{{x[\"citation_key\"]}}}', axis=1)\n",
    "regr_datasets = regr_datasets.drop('citation_key', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrr}\n",
      " & name & n & n-col & n-grid \\\\\n",
      "0 & haberman \\cite{keel} & 306 & 3 & 2 \\\\\n",
      "1 & new-thyroid1 \\cite{keel} & 215 & 5 & 1 \\\\\n",
      "2 & shuttle-6-vs-2-3 \\cite{keel} & 230 & 9 & 4 \\\\\n",
      "3 & bupa \\cite{keel} & 345 & 6 & 4 \\\\\n",
      "4 & cleveland-0-vs-4 \\cite{keel} & 177 & 13 & 7 \\\\\n",
      "5 & ecoli1 \\cite{keel} & 336 & 7 & 1 \\\\\n",
      "6 & poker-9-vs-7 \\cite{keel} & 244 & 10 & 10 \\\\\n",
      "7 & monk-2 \\cite{keel} & 432 & 6 & 4 \\\\\n",
      "8 & hepatitis \\cite{krnn} & 155 & 19 & 1 \\\\\n",
      "9 & yeast-0-3-5-9-vs-7-8 \\cite{keel} & 506 & 8 & 2 \\\\\n",
      "10 & mammographic \\cite{keel} & 830 & 5 & 4 \\\\\n",
      "11 & saheart \\cite{keel} & 462 & 9 & 3 \\\\\n",
      "12 & lymphography-normal-fibrosis \\cite{keel} & 148 & 32 & 3 \\\\\n",
      "13 & pima \\cite{keel} & 768 & 8 & 5 \\\\\n",
      "14 & wisconsin \\cite{keel} & 683 & 9 & 9 \\\\\n",
      "15 & abalone9-18 \\cite{keel} & 731 & 9 & 3 \\\\\n",
      "16 & winequality-red-3-vs-5 \\cite{keel} & 691 & 11 & 3 \\\\\n",
      "17 & CM1 \\cite{krnn} & 498 & 21 & 1 \\\\\n",
      "18 & australian \\cite{keel} & 690 & 16 & 2 \\\\\n",
      "19 & SPECTF \\cite{krnn} & 267 & 44 & 42 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(binclas_datasets[['name', 'n', 'n_col', 'n_grid']].style.to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrr}\n",
      " & name & n & n-col & n-grid \\\\\n",
      "0 & o-ring \\cite{uci} & 23 & 6 & 3 \\\\\n",
      "1 & stock-portfolio-performance \\cite{uci} & 63 & 6 & 1 \\\\\n",
      "2 & wsn-ale \\cite{uci} & 107 & 5 & 1 \\\\\n",
      "3 & daily-demand \\cite{uci} & 60 & 12 & 2 \\\\\n",
      "4 & servo \\cite{uci} & 167 & 10 & 2 \\\\\n",
      "5 & yacht-hydrodynamics \\cite{krnn} & 307 & 6 & 1 \\\\\n",
      "6 & autoMPG6 \\cite{keel} & 392 & 5 & 2 \\\\\n",
      "7 & excitation-current \\cite{uci} & 557 & 4 & 2 \\\\\n",
      "8 & real-estate-valuation \\cite{uci} & 414 & 6 & 2 \\\\\n",
      "9 & wankara \\cite{keel} & 321 & 9 & 2 \\\\\n",
      "10 & plastic \\cite{keel} & 1650 & 2 & 2 \\\\\n",
      "11 & laser \\cite{keel} & 993 & 4 & 4 \\\\\n",
      "12 & qsar-aquatic-toxicity \\cite{uci} & 546 & 8 & 3 \\\\\n",
      "13 & baseball \\cite{keel} & 337 & 16 & 10 \\\\\n",
      "14 & maternal-health-risk \\cite{uci} & 1013 & 6 & 1 \\\\\n",
      "15 & medical-cost \\cite{mlwithr} & 1338 & 6 & 1 \\\\\n",
      "16 & boom-bikes \\cite{boombikes} & 730 & 13 & 4 \\\\\n",
      "17 & wizmir \\cite{keel} & 1461 & 9 & 2 \\\\\n",
      "18 & forestfires \\cite{krnn} & 517 & 27 & 3 \\\\\n",
      "19 & winequality-red \\cite{krnn} & 1599 & 11 & 4 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(regr_datasets[['name', 'n', 'n_col', 'n_grid']].style.to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([binclas_datasets[['name', 'n', 'n_col', 'n_grid']], regr_datasets[['name', 'n', 'n_col', 'n_grid']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "columns = [np.array(['Classification', 'Classification', 'Classification', 'Classification', 'Regression', 'Regression', 'Regression', 'Regression']),\n",
    "            np.array(['name', 'n', 'n_col', 'n_grid', 'name', 'n', 'n_col', 'n_grid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrlrrr}\n",
      " & \\multicolumn{4}{r}{Classification} & \\multicolumn{4}{r}{Regression} \\\\\n",
      " & name & n & n-col & n-grid & name & n & n-col & n-grid \\\\\n",
      "0 & haberman \\cite{keel} & 306 & 3 & 2 & o-ring \\cite{uci} & 23 & 6 & 3 \\\\\n",
      "1 & new-thyroid1 \\cite{keel} & 215 & 5 & 1 & stock-portfolio-performance \\cite{uci} & 63 & 6 & 1 \\\\\n",
      "2 & shuttle-6-vs-2-3 \\cite{keel} & 230 & 9 & 4 & wsn-ale \\cite{uci} & 107 & 5 & 1 \\\\\n",
      "3 & bupa \\cite{keel} & 345 & 6 & 4 & daily-demand \\cite{uci} & 60 & 12 & 2 \\\\\n",
      "4 & cleveland-0-vs-4 \\cite{keel} & 177 & 13 & 7 & servo \\cite{uci} & 167 & 10 & 2 \\\\\n",
      "5 & ecoli1 \\cite{keel} & 336 & 7 & 1 & yacht-hydrodynamics \\cite{krnn} & 307 & 6 & 1 \\\\\n",
      "6 & poker-9-vs-7 \\cite{keel} & 244 & 10 & 10 & autoMPG6 \\cite{keel} & 392 & 5 & 2 \\\\\n",
      "7 & monk-2 \\cite{keel} & 432 & 6 & 4 & excitation-current \\cite{uci} & 557 & 4 & 2 \\\\\n",
      "8 & hepatitis \\cite{krnn} & 155 & 19 & 1 & real-estate-valuation \\cite{uci} & 414 & 6 & 2 \\\\\n",
      "9 & yeast-0-3-5-9-vs-7-8 \\cite{keel} & 506 & 8 & 2 & wankara \\cite{keel} & 321 & 9 & 2 \\\\\n",
      "10 & mammographic \\cite{keel} & 830 & 5 & 4 & plastic \\cite{keel} & 1650 & 2 & 2 \\\\\n",
      "11 & saheart \\cite{keel} & 462 & 9 & 3 & laser \\cite{keel} & 993 & 4 & 4 \\\\\n",
      "12 & lymphography-normal-fibrosis \\cite{keel} & 148 & 32 & 3 & qsar-aquatic-toxicity \\cite{uci} & 546 & 8 & 3 \\\\\n",
      "13 & pima \\cite{keel} & 768 & 8 & 5 & baseball \\cite{keel} & 337 & 16 & 10 \\\\\n",
      "14 & wisconsin \\cite{keel} & 683 & 9 & 9 & maternal-health-risk \\cite{uci} & 1013 & 6 & 1 \\\\\n",
      "15 & abalone9-18 \\cite{keel} & 731 & 9 & 3 & medical-cost \\cite{mlwithr} & 1338 & 6 & 1 \\\\\n",
      "16 & winequality-red-3-vs-5 \\cite{keel} & 691 & 11 & 3 & boom-bikes \\cite{boombikes} & 730 & 13 & 4 \\\\\n",
      "17 & CM1 \\cite{krnn} & 498 & 21 & 1 & wizmir \\cite{keel} & 1461 & 9 & 2 \\\\\n",
      "18 & australian \\cite{keel} & 690 & 16 & 2 & forestfires \\cite{krnn} & 517 & 27 & 3 \\\\\n",
      "19 & SPECTF \\cite{krnn} & 267 & 44 & 42 & winequality-red \\cite{krnn} & 1599 & 11 & 4 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tmp.style.to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@article{krnn,\n",
      "author={X. J. Zhang and Z. Tari and M. Cheriet},\n",
      "title={{KRNN}: k {Rare-class Nearest Neighbor} classification},\n",
      "journal={Pattern Recognition},\n",
      "year={2017},\n",
      "volume={62},\n",
      "number={2},\n",
      "pages={33--44}\n",
      "}\n",
      "@article{keel,\n",
      "author={Alcala-Fdez, J. and Fernandez, A. and Luengo, J. and Derrac, J. and Garcia, S. and Sanchez, L. and Herrera, F.},\n",
      "title={KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework},\n",
      "journal={Journal of Multiple-Valued Logic and Soft Computing},\n",
      "volume={17},\n",
      "number={2-3},\n",
      "year={2011},\n",
      "pages={255-287}\n",
      "}\n",
      "\n",
      "\n",
      "@misc{uci,\n",
      "author = \"Dua, Dheeru and Karra Taniskidou, Efi\",\n",
      "year = \"2017\",\n",
      "title = \"{UCI} Machine Learning Repository\",\n",
      "url = \"http://archive.ics.uci.edu/ml\",\n",
      "institution = \"University of California, Irvine, School of Information and Computer Sciences\" }\n",
      "\n",
      "\n",
      "@article{boombikes,\n",
      "\tyear={2013},\n",
      "\tissn={2192-6352},\n",
      "\tjournal={Progress in Artificial Intelligence},\n",
      "\tdoi={10.1007/s13748-013-0040-3},\n",
      "\ttitle={Event labeling combining ensemble detectors and background knowledge},\n",
      "\turl={http://dx.doi.org/10.1007/s13748-013-0040-3},\n",
      "\tpublisher={Springer Berlin Heidelberg},\n",
      "\tkeywords={Event labeling; Event detection; Ensemble learning; Background knowledge},\n",
      "\tauthor={Fanaee-T, Hadi and Gama, Joao},\n",
      "\tpages={1-15}\n",
      "}\n",
      "\n",
      "\n",
      "@book{mlwithr,\n",
      "author = {Lantz, Brett},\n",
      "title = {Machine Learning with R},\n",
      "year = {2013},\n",
      "isbn = {1782162143},\n",
      "publisher = {Packt Publishing}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in common_datasets.references:\n",
    "    print(common_datasets.references[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_dt = pd.read_csv('existance-classification-dt.csv')\n",
    "regr_dt = pd.read_csv('existance-regression-dt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_dt = clas_dt[['name', 'auc_orig', 'auc_flipped', 'p_full']]\n",
    "regr_dt = regr_dt[['name', 'r2_orig', 'r2_flipped', 'p_full']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([clas_dt, regr_dt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "columns = [np.array(['Classification', 'Classification', 'Classification', 'Classification', 'Regression', 'Regression', 'Regression', 'Regression']),\n",
    "            np.array(['name', 'auc_orig', 'auc_flipped', 'p', 'name', 'r2_orig', 'r2_flipped', 'p'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_p(p):\n",
    "    if p < 0.05 or p > 0.95:\n",
    "        return '{\\\\bf %.3f}' % p\n",
    "    return '%.3f' % p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrlrrr}\n",
      "\\multicolumn{4}{r}{Classification} & \\multicolumn{4}{r}{Regression} \\\\\n",
      "name & auc-orig & auc-flipped & p & name & r2-orig & r2-flipped & p \\\\\n",
      "haberman & 0.5588 & 0.5613 & {\\bf 0.0066} & o-ring & 0.1112 & 0.2528 & {\\bf 0.0000} \\\\\n",
      "new-thyroid1 & 0.9305 & 0.9320 & {\\bf 0.0048} & stock-portfolio-performance & 0.9869 & 0.9867 & 0.4986 \\\\\n",
      "shuttle-6-vs-2-3 & 1.0000 & 1.0000 & 0.5000 & wsn-ale & -0.0659 & -0.1085 & 0.8774 \\\\\n",
      "bupa & 0.6252 & 0.6237 & 0.9431 & daily-demand & 0.6608 & 0.6792 & {\\bf 0.0003} \\\\\n",
      "cleveland-0-vs-4 & 0.6707 & 0.6769 & {\\bf 0.0383} & servo & 0.4696 & 0.4692 & {\\bf 1.0000} \\\\\n",
      "ecoli1 & 0.8324 & 0.8308 & {\\bf 0.9930} & yacht-hydrodynamics & 0.9921 & 0.9922 & 0.0586 \\\\\n",
      "poker-9-vs-7 & 0.6069 & 0.6067 & {\\bf 0.0000} & autoMPG6 & 0.7657 & 0.7660 & 0.3579 \\\\\n",
      "monk-2 & 1.0000 & 1.0000 & 0.5000 & excitation-current & 0.9998 & 0.9998 & 0.1582 \\\\\n",
      "hepatitis & 0.6665 & 0.6669 & 0.2960 & real-estate-valuation & 0.4594 & 0.4746 & {\\bf 0.0000} \\\\\n",
      "yeast-0-3-5-9-vs-7-8 & 0.6403 & 0.6404 & 0.1913 & wankara & 0.9696 & 0.9696 & 0.4523 \\\\\n",
      "mammographic & 0.7880 & 0.7883 & 0.1590 & plastic & 0.6485 & 0.6319 & {\\bf 1.0000} \\\\\n",
      "saheart & 0.5828 & 0.5833 & 0.4432 & laser & 0.9215 & 0.9233 & {\\bf 0.0004} \\\\\n",
      "lymphography-normal-fibrosis & 0.8840 & 0.8890 & 0.2601 & qsar-aquatic-toxicity & 0.1201 & 0.1260 & {\\bf 0.0012} \\\\\n",
      "pima & 0.6707 & 0.6699 & 0.9416 & baseball & 0.4007 & 0.3974 & 0.9083 \\\\\n",
      "wisconsin & 0.9372 & 0.9389 & {\\bf 0.0000} & maternal-health-risk & 0.7143 & 0.7135 & {\\bf 0.9740} \\\\\n",
      "abalone9-18 & 0.6477 & 0.6489 & 0.1488 & medical-cost & 0.5281 & 0.5280 & 0.5693 \\\\\n",
      "winequality-red-3-vs-5 & 0.5143 & 0.5143 & 0.8903 & boom-bikes & 0.9872 & 0.9871 & 0.6211 \\\\\n",
      "CM1 & 0.5674 & 0.5673 & 0.7217 & wizmir & 0.9843 & 0.9844 & {\\bf 0.0102} \\\\\n",
      "australian & 0.8066 & 0.8061 & 0.8176 & forestfires & -6.2655 & -9.7147 & {\\bf 1.0000} \\\\\n",
      "SPECTF & 0.6138 & 0.6159 & {\\bf 0.0328} & winequality-red & 0.0347 & 0.0362 & 0.1230 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tmp.style\\\n",
    "    .format(subset=[('Classification', 'auc_orig')], precision=4)\\\n",
    "    .format(subset=[('Classification', 'auc_flipped')], precision=4)\\\n",
    "    .format(subset=[('Classification', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Regression', 'r2_orig')], precision=4)\\\n",
    "    .format(subset=[('Regression', 'r2_flipped')], precision=4)\\\n",
    "    .format(subset=[('Regression', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .hide(level=0, axis=0)\\\n",
    "    .to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_rf = pd.read_csv('existance-classification-rf.csv')\n",
    "regr_rf = pd.read_csv('existance-regression-rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_rf = clas_rf[['name', 'auc_orig', 'auc_flipped', 'p_full']]\n",
    "regr_rf = regr_rf[['name', 'r2_orig', 'r2_flipped', 'p_full']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([clas_rf, regr_rf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "columns = [np.array(['Classification', 'Classification', 'Classification', 'Classification', 'Regression', 'Regression', 'Regression', 'Regression']),\n",
    "            np.array(['name', 'auc_orig', 'auc_flipped', 'p', 'name', 'r2_orig', 'r2_flipped', 'p'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrlrrr}\n",
      "\\multicolumn{4}{r}{Classification} & \\multicolumn{4}{r}{Regression} \\\\\n",
      "name & auc-orig & auc-flipped & p & name & r2-orig & r2-flipped & p \\\\\n",
      "haberman & 0.6681 & 0.6718 & {\\bf 0.0000} & autoMPG6 & 0.8721 & 0.8717 & {\\bf 0.9991} \\\\\n",
      "new-thyroid1 & 0.9992 & 0.9990 & {\\bf 0.9978} & baseball & 0.6682 & 0.6666 & {\\bf 0.9996} \\\\\n",
      "shuttle-6-vs-2-3 & 1.0000 & 1.0000 & 0.3783 & boom-bikes & 0.9961 & 0.9961 & 0.0873 \\\\\n",
      "bupa & 0.7636 & 0.7625 & {\\bf 0.9900} & daily-demand & 0.8209 & 0.8254 & {\\bf 0.0000} \\\\\n",
      "cleveland-0-vs-4 & 0.9720 & 0.9746 & {\\bf 0.0000} & excitation-current & 0.9999 & 0.9999 & {\\bf 0.0000} \\\\\n",
      "ecoli1 & 0.9541 & 0.9544 & 0.1573 & laser & 0.9631 & 0.9633 & {\\bf 0.0139} \\\\\n",
      "poker-9-vs-7 & 0.9849 & 0.9869 & {\\bf 0.0000} & maternal-health-risk & 0.7524 & 0.7539 & {\\bf 0.0000} \\\\\n",
      "monk-2 & 1.0000 & 1.0000 & 0.2854 & medical-cost & 0.6940 & 0.6934 & {\\bf 1.0000} \\\\\n",
      "hepatitis & 0.8763 & 0.8767 & 0.1405 & o-ring & 0.1416 & 0.1689 & {\\bf 0.0000} \\\\\n",
      "yeast-0-3-5-9-vs-7-8 & 0.7942 & 0.7933 & 0.9174 & plastic & 0.7151 & 0.7101 & {\\bf 1.0000} \\\\\n",
      "mammographic & 0.8677 & 0.8678 & 0.1128 & qsar-aquatic-toxicity & 0.5242 & 0.5242 & 0.6750 \\\\\n",
      "saheart & 0.7221 & 0.7220 & 0.6956 & real-estate-valuation & 0.6931 & 0.6937 & 0.4486 \\\\\n",
      "lymphography-normal-fibrosis & 0.9939 & 0.9948 & {\\bf 0.0007} & residential-building & 0.9582 & 0.9576 & {\\bf 1.0000} \\\\\n",
      "pima & 0.8235 & 0.8235 & 0.4972 & servo & 0.6332 & 0.6323 & 0.7671 \\\\\n",
      "wisconsin & 0.9927 & 0.9930 & {\\bf 0.0000} & stock-portfolio-performance & 0.9916 & 0.9912 & {\\bf 0.9954} \\\\\n",
      "abalone9-18 & 0.8316 & 0.8288 & {\\bf 0.9999} & wankara & 0.9872 & 0.9872 & 0.4402 \\\\\n",
      "winequality-red-3-vs-5 & 0.7380 & 0.7367 & 0.5483 & winequality-red & 0.4799 & 0.4791 & {\\bf 0.9974} \\\\\n",
      "CM1 & 0.7553 & 0.7538 & {\\bf 0.9938} & wizmir & 0.9923 & 0.9923 & {\\bf 0.0042} \\\\\n",
      "australian & 0.9265 & 0.9270 & {\\bf 0.0006} & wsn-ale & 0.5258 & 0.5246 & 0.0602 \\\\\n",
      "SPECTF & 0.8412 & 0.8415 & 0.3237 & yacht-hydrodynamics & 0.9948 & 0.9948 & {\\bf 0.0000} \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tmp.style\\\n",
    "    .format(subset=[('Classification', 'auc_orig')], precision=4)\\\n",
    "    .format(subset=[('Classification', 'auc_flipped')], precision=4)\\\n",
    "    .format(subset=[('Classification', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Regression', 'r2_orig')], precision=4)\\\n",
    "    .format(subset=[('Regression', 'r2_flipped')], precision=4)\\\n",
    "    .format(subset=[('Regression', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .hide(level=0, axis=0)\\\n",
    "    .to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [np.array(['Classification', \n",
    "                     'Classification', \n",
    "                     'Classification', \n",
    "                     'Classification', \n",
    "                     'Classification', \n",
    "                     'Classification', \n",
    "                     'Classification', \n",
    "                     'Regression', \n",
    "                     'Regression', \n",
    "                     'Regression', \n",
    "                     'Regression',\n",
    "                     'Regression', \n",
    "                     'Regression', \n",
    "                     'Regression']),\n",
    "            np.array(['DT',\n",
    "                        'DT',\n",
    "                        'DT',\n",
    "                        'DT',\n",
    "                        'RF',\n",
    "                        'RF',\n",
    "                        'RF',\n",
    "                        'DT',\n",
    "                        'DT',\n",
    "                        'DT',\n",
    "                        'DT',\n",
    "                        'RF',\n",
    "                        'RF',\n",
    "                        'RF']),\n",
    "            np.array(['name', \n",
    "                        'auc_orig', \n",
    "                        'auc_flipped', \n",
    "                        'p', \n",
    "                        'auc_orig', \n",
    "                        'auc_flipped', \n",
    "                        'p', \n",
    "                        'name', \n",
    "                        'r2_orig', \n",
    "                        'r2_flipped', \n",
    "                        'p',\n",
    "                        'r2_orig', \n",
    "                        'r2_flipped', \n",
    "                        'p'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([clas_dt, clas_rf.drop(columns='name'), regr_dt, regr_rf.drop(columns='name')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrlrrrrrr}\n",
      "\\multicolumn{7}{r}{Classification} & \\multicolumn{7}{r}{Regression} \\\\\n",
      "\\multicolumn{4}{r}{DT} & \\multicolumn{3}{r}{RF} & \\multicolumn{4}{r}{DT} & \\multicolumn{3}{r}{RF} \\\\\n",
      "name & auc-orig & auc-flipped & p & auc-orig & auc-flipped & p & name & r2-orig & r2-flipped & p & r2-orig & r2-flipped & p \\\\\n",
      "haberman & 0.559 & 0.561 & {\\bf 0.007} & 0.668 & 0.672 & {\\bf 0.000} & o-ring & 0.111 & 0.253 & {\\bf 0.000} & 0.872 & 0.872 & {\\bf 0.999} \\\\\n",
      "new-thyroid1 & 0.931 & 0.932 & {\\bf 0.005} & 0.999 & 0.999 & {\\bf 0.998} & stock-portfolio-performance & 0.987 & 0.987 & 0.499 & 0.668 & 0.667 & {\\bf 1.000} \\\\\n",
      "shuttle-6-vs-2-3 & 1.000 & 1.000 & 0.500 & 1.000 & 1.000 & 0.378 & wsn-ale & -0.066 & -0.109 & 0.877 & 0.996 & 0.996 & 0.087 \\\\\n",
      "bupa & 0.625 & 0.624 & 0.943 & 0.764 & 0.762 & {\\bf 0.990} & daily-demand & 0.661 & 0.679 & {\\bf 0.000} & 0.821 & 0.825 & {\\bf 0.000} \\\\\n",
      "cleveland-0-vs-4 & 0.671 & 0.677 & {\\bf 0.038} & 0.972 & 0.975 & {\\bf 0.000} & servo & 0.470 & 0.469 & {\\bf 1.000} & 1.000 & 1.000 & {\\bf 0.000} \\\\\n",
      "ecoli1 & 0.832 & 0.831 & {\\bf 0.993} & 0.954 & 0.954 & 0.157 & yacht-hydrodynamics & 0.992 & 0.992 & 0.059 & 0.963 & 0.963 & {\\bf 0.014} \\\\\n",
      "poker-9-vs-7 & 0.607 & 0.607 & {\\bf 0.000} & 0.985 & 0.987 & {\\bf 0.000} & autoMPG6 & 0.766 & 0.766 & 0.358 & 0.752 & 0.754 & {\\bf 0.000} \\\\\n",
      "monk-2 & 1.000 & 1.000 & 0.500 & 1.000 & 1.000 & 0.285 & excitation-current & 1.000 & 1.000 & 0.158 & 0.694 & 0.693 & {\\bf 1.000} \\\\\n",
      "hepatitis & 0.667 & 0.667 & 0.296 & 0.876 & 0.877 & 0.141 & real-estate-valuation & 0.459 & 0.475 & {\\bf 0.000} & 0.142 & 0.169 & {\\bf 0.000} \\\\\n",
      "yeast-0-3-5-9-vs-7-8 & 0.640 & 0.640 & 0.191 & 0.794 & 0.793 & 0.917 & wankara & 0.970 & 0.970 & 0.452 & 0.715 & 0.710 & {\\bf 1.000} \\\\\n",
      "mammographic & 0.788 & 0.788 & 0.159 & 0.868 & 0.868 & 0.113 & plastic & 0.649 & 0.632 & {\\bf 1.000} & 0.524 & 0.524 & 0.675 \\\\\n",
      "saheart & 0.583 & 0.583 & 0.443 & 0.722 & 0.722 & 0.696 & laser & 0.922 & 0.923 & {\\bf 0.000} & 0.693 & 0.694 & 0.449 \\\\\n",
      "lymphography-normal-fibrosis & 0.884 & 0.889 & 0.260 & 0.994 & 0.995 & {\\bf 0.001} & qsar-aquatic-toxicity & 0.120 & 0.126 & {\\bf 0.001} & 0.958 & 0.958 & {\\bf 1.000} \\\\\n",
      "pima & 0.671 & 0.670 & 0.942 & 0.824 & 0.824 & 0.497 & baseball & 0.401 & 0.397 & 0.908 & 0.633 & 0.632 & 0.767 \\\\\n",
      "wisconsin & 0.937 & 0.939 & {\\bf 0.000} & 0.993 & 0.993 & {\\bf 0.000} & maternal-health-risk & 0.714 & 0.714 & {\\bf 0.974} & 0.992 & 0.991 & {\\bf 0.995} \\\\\n",
      "abalone9-18 & 0.648 & 0.649 & 0.149 & 0.832 & 0.829 & {\\bf 1.000} & medical-cost & 0.528 & 0.528 & 0.569 & 0.987 & 0.987 & 0.440 \\\\\n",
      "winequality-red-3-vs-5 & 0.514 & 0.514 & 0.890 & 0.738 & 0.737 & 0.548 & boom-bikes & 0.987 & 0.987 & 0.621 & 0.480 & 0.479 & {\\bf 0.997} \\\\\n",
      "CM1 & 0.567 & 0.567 & 0.722 & 0.755 & 0.754 & {\\bf 0.994} & wizmir & 0.984 & 0.984 & {\\bf 0.010} & 0.992 & 0.992 & {\\bf 0.004} \\\\\n",
      "australian & 0.807 & 0.806 & 0.818 & 0.927 & 0.927 & {\\bf 0.001} & forestfires & -6.266 & -9.715 & {\\bf 1.000} & 0.526 & 0.525 & 0.060 \\\\\n",
      "SPECTF & 0.614 & 0.616 & {\\bf 0.033} & 0.841 & 0.842 & 0.324 & winequality-red & 0.035 & 0.036 & 0.123 & 0.995 & 0.995 & {\\bf 0.000} \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tmp.style\\\n",
    "    .format(subset=[('Classification', 'DT', 'auc_orig')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'DT', 'auc_flipped')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'DT', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Classification', 'RF', 'auc_orig')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'RF', 'auc_flipped')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'RF', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Regression', 'DT', 'r2_orig')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'DT', 'r2_flipped')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'DT', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Regression', 'RF', 'r2_orig')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'RF', 'r2_flipped')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'RF', 'p')], formatter=format_p, escape='latex')\\\n",
    "    .hide(level=0, axis=0)\\\n",
    "    .to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_rf = pd.read_csv('classification.csv')\n",
    "regr_rf = pd.read_csv('regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'name', 'auc_orig', 'auc_flipped', 'auc_baseline',\n",
       "       'auc_baseline_flipped', 'auc_flipping_full', 'auc_flipping_coord',\n",
       "       'aucs_orig', 'aucs_flipped', 'aucs_baseline', 'aucs_baseline_flipped',\n",
       "       'aucs_flipping_full', 'aucs_flipping_coord', 'p_full', 'p_coord',\n",
       "       'auc_baseline_min', 'auc_baseline_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_rf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'name', 'r2_orig', 'r2_flipped', 'r2_baseline',\n",
       "       'r2_baseline_flipped', 'r2_flipping_full', 'r2_flipping_coord',\n",
       "       'r2s_orig', 'r2s_flipped', 'r2s_baseline', 'r2s_baseline_flipped',\n",
       "       'r2s_flipping_full', 'r2s_flipping_coord', 'p_full', 'p_coord',\n",
       "       'r2_baseline_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_rf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_rf = clas_rf[['name', 'auc_baseline', 'auc_flipping_full', 'auc_flipping_coord', 'p_full', 'p_coord']]\n",
    "regr_rf = regr_rf[['name', 'r2_baseline', 'r2_flipping_full', 'r2_flipping_coord', 'p_full', 'p_coord']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([clas_rf, regr_rf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "columns = [np.array(['Classification'] * len(clas_rf.columns) + \\\n",
    "                    ['Regression'] * len(regr_rf.columns)),\n",
    "            np.array(list(clas_rf.columns) + list(regr_rf.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'auc_baseline', 'auc_flipping_full', 'auc_flipping_coord',\n",
       "       'p_full', 'p_coord', 'name', 'r2_baseline', 'r2_flipping_full',\n",
       "       'r2_flipping_coord', 'p_full', 'p_coord'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Classification', 'Classification', 'Classification',\n",
       "        'Classification', 'Classification', 'Classification', 'Regression',\n",
       "        'Regression', 'Regression', 'Regression', 'Regression',\n",
       "        'Regression'], dtype='<U14'),\n",
       " array(['name', 'auc_baseline', 'auc_flipping_full', 'auc_flipping_coord',\n",
       "        'p_full', 'p_coord', 'name', 'r2_baseline', 'r2_flipping_full',\n",
       "        'r2_flipping_coord', 'p_full', 'p_coord'], dtype='<U18')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrlrrrrr}\n",
      "\\multicolumn{6}{r}{Classification} & \\multicolumn{6}{r}{Regression} \\\\\n",
      "name & auc-baseline & auc-flipping-full & auc-flipping-coord & p-full & p-coord & name & r2-baseline & r2-flipping-full & r2-flipping-coord & p-full & p-coord \\\\\n",
      "haberman & 0.669 & 0.671 & 0.671 & {\\bf 0.000} & {\\bf 0.000} & autoMPG6 & 0.872 & 0.872 & 0.872 & 0.437 & 0.603 \\\\\n",
      "new-thyroid1 & 0.999 & 0.999 & 0.999 & 0.812 & 0.904 & baseball & 0.668 & 0.668 & 0.667 & 0.852 & 0.876 \\\\\n",
      "shuttle-6-vs-2-3 & 1.000 & 1.000 & 1.000 & 0.518 & 0.464 & boom-bikes & 0.996 & 0.996 & 0.996 & 0.296 & 0.340 \\\\\n",
      "bupa & 0.764 & 0.763 & 0.763 & {\\bf 1.000} & {\\bf 0.978} & daily-demand & 0.819 & 0.822 & 0.824 & {\\bf 0.000} & {\\bf 0.000} \\\\\n",
      "cleveland-0-vs-4 & 0.972 & 0.974 & 0.973 & {\\bf 0.000} & {\\bf 0.000} & excitation-current & 1.000 & 1.000 & 1.000 & {\\bf 0.000} & {\\bf 0.000} \\\\\n",
      "ecoli1 & 0.954 & 0.954 & 0.955 & 0.145 & 0.086 & laser & 0.963 & 0.963 & 0.963 & {\\bf 0.000} & {\\bf 0.002} \\\\\n",
      "poker-9-vs-7 & 0.986 & 0.987 & 0.986 & {\\bf 0.000} & {\\bf 0.006} & maternal-health-risk & 0.753 & 0.753 & 0.753 & {\\bf 0.000} & {\\bf 0.000} \\\\\n",
      "monk-2 & 1.000 & 1.000 & 1.000 & 0.154 & 0.143 & medical-cost & 0.694 & 0.694 & 0.694 & 0.171 & 0.110 \\\\\n",
      "hepatitis & 0.876 & 0.876 & 0.876 & 0.405 & 0.345 & o-ring & 0.140 & 0.157 & 0.158 & {\\bf 0.000} & {\\bf 0.000} \\\\\n",
      "yeast-0-3-5-9-vs-7-8 & 0.795 & 0.794 & 0.795 & 0.867 & 0.822 & plastic & 0.715 & 0.714 & 0.714 & {\\bf 1.000} & {\\bf 1.000} \\\\\n",
      "mammographic & 0.868 & 0.868 & 0.868 & {\\bf 0.000} & {\\bf 0.000} & qsar-aquatic-toxicity & 0.524 & 0.524 & 0.525 & 0.244 & {\\bf 0.013} \\\\\n",
      "saheart & 0.722 & 0.722 & 0.722 & 0.834 & 0.633 & real-estate-valuation & 0.693 & 0.693 & 0.694 & {\\bf 0.984} & 0.345 \\\\\n",
      "lymphography-normal-fibrosis & 0.994 & 0.995 & 0.995 & {\\bf 0.003} & {\\bf 0.007} & residential-building & 0.958 & 0.958 & 0.958 & 0.677 & 0.520 \\\\\n",
      "pima & 0.823 & 0.823 & 0.823 & 0.424 & 0.858 & servo & 0.631 & 0.631 & 0.630 & 0.233 & 0.653 \\\\\n",
      "wisconsin & 0.993 & 0.993 & 0.993 & {\\bf 0.002} & {\\bf 0.011} & stock-portfolio-performance & 0.992 & 0.991 & 0.992 & 0.893 & 0.197 \\\\\n",
      "abalone9-18 & 0.831 & 0.830 & 0.831 & 0.949 & 0.793 & wankara & 0.987 & 0.987 & 0.987 & {\\bf 0.002} & {\\bf 0.002} \\\\\n",
      "winequality-red-3-vs-5 & 0.742 & 0.739 & 0.737 & 0.855 & {\\bf 0.993} & winequality-red & 0.480 & 0.479 & 0.479 & 0.775 & {\\bf 0.971} \\\\\n",
      "CM1 & 0.755 & 0.754 & 0.755 & {\\bf 0.981} & 0.646 & wizmir & 0.992 & 0.992 & 0.992 & {\\bf 0.003} & {\\bf 0.000} \\\\\n",
      "australian & 0.926 & 0.927 & 0.927 & {\\bf 0.046} & {\\bf 0.028} & wsn-ale & 0.523 & 0.526 & 0.525 & {\\bf 0.001} & {\\bf 0.018} \\\\\n",
      "SPECTF & 0.840 & 0.841 & 0.841 & 0.202 & {\\bf 0.041} & yacht-hydrodynamics & 0.995 & 0.995 & 0.995 & {\\bf 0.004} & {\\bf 0.032} \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tmp.style\\\n",
    "    .format(subset=[('Classification', 'auc_baseline')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'auc_flipping_full')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'auc_flipping_coord')], precision=3)\\\n",
    "    .format(subset=[('Classification', 'p_full')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Classification', 'p_coord')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Regression', 'r2_baseline')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'r2_flipping_full')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'r2_flipping_coord')], precision=3)\\\n",
    "    .format(subset=[('Regression', 'p_full')], formatter=format_p, escape='latex')\\\n",
    "    .format(subset=[('Regression', 'p_coord')], formatter=format_p, escape='latex')\\\n",
    "    .hide(level=0, axis=0)\\\n",
    "    .to_latex().replace('_', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smote_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "499044d5ebe425087106556eea30a149e28227c692f9b3f42bc5fd0f94503385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
